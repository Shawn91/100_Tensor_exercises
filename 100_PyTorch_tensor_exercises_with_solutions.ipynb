{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 100 PyTorch Tensor exercises\n",
    "\n",
    "这里有 100 道关于 PyTorch Tensor 的练习题。原题来自于 https://github.com/rougier/numpy-100 ，是关于 Numpy 的练习题。\n",
    "\n",
    "我将题目翻译成中文，并提供了 PyTorch Tensor 的da'an"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File automatically generated. See the documentation to update questions/answers/hints programmatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the `initialize.py` module, then for each question you can query the\n",
    "answer or an hint with `hint(n)` or `answer(n)` for `n` question number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run initialise.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 导入 PyTorch (★☆☆)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 显示 PyTorch 当前版本 (★☆☆)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 创建一个长度为 10，每个元素值都为 0 的一维 Tensor (★☆☆)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros([10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. 计算任意 Tensor 的内存占用 (★☆☆)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 bytes\n"
     ]
    }
   ],
   "source": [
    "t = torch.zeros([10,3])\n",
    "print('%d bytes' % (t.element_size() * t.nelement()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. 如何通过命令行获取 PyTorch 函数的帮助文档 (★☆☆)\n",
    "该问题目前似乎无解。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. 创建一个长度为 10 的一维 Tensor，除了第五个元素是 1 外，其他元素都是 0(★☆☆)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.zeros([10])\n",
    "t[4] = 1\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. 创建一个元素值依次为 10 到 49 的一维 Tensor(★☆☆)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,\n",
       "        28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45,\n",
       "        46, 47, 48, 49])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(10, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. 将一个一维 Tensor 翻转（`[1,2,3]` 变为 `[3,2,1]`）(★☆☆)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([19, 18, 17, 16, 15, 14, 13, 12, 11, 10])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.arange(10, 20)\n",
    "t.flip(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. 创建一个 3\\*3 的二维 Tensor，值为 0 到 8 (★☆☆)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [3, 4, 5],\n",
       "        [6, 7, 8]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(9).view([3,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. 获取 [1,2,0,0,4,0] 中非零元素的下标(★☆☆)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [1],\n",
       "        [4]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.Tensor([1,2,0,0,4,0])\n",
    "t.nonzero()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. 创建一个 3\\*3 的 单位矩阵（identity matrix） (★☆☆)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12. 创建一个 3x3x3 的随机 Tensor (★☆☆)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3535, 0.6218, 0.2071],\n",
       "         [0.4987, 0.3297, 0.3077],\n",
       "         [0.8799, 0.7423, 0.5187]],\n",
       "\n",
       "        [[0.1057, 0.6544, 0.6071],\n",
       "         [0.3751, 0.9311, 0.5071],\n",
       "         [0.7958, 0.1009, 0.9900]],\n",
       "\n",
       "        [[0.5937, 0.0500, 0.8445],\n",
       "         [0.2194, 0.5079, 0.4057],\n",
       "         [0.4983, 0.8374, 0.4039]]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand([3,3,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13. 创建一个 10x10 的随机 Tensor，并找出其中的最大值和最小值(★☆☆)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9926)\n",
      "tensor(0.0224)\n"
     ]
    }
   ],
   "source": [
    "t = torch.rand([10, 10])\n",
    "print(t.max())\n",
    "print(t.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14. 创建一个长度为 30 的随机一维 Tensor，并计算平均值(★☆☆)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4501)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.rand([30])\n",
    "t.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 15. 创建一个二维 Tensor，最外围元素是 1，内部元素都是 0 (★☆☆)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 0., 1.],\n",
       "        [1., 0., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.ones([4,3])\n",
    "t[1:-1,1:-1] = 0\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 16. 对一个已有 Tensor 外围添加一圈 0 (★☆☆)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 1., 1., 0.],\n",
       "        [0., 1., 1., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.ones([2,2])\n",
    "torch.nn.functional.pad(t, (1,1,1,1), mode='constant', value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 17. 以下代码的运行结果是什么？ (★☆☆)\n",
    "```python\n",
    "0 * torch.Tensor([float('NaN')])\n",
    "torch.Tensor([float('NaN')]) == torch.Tensor([float('NaN')])\n",
    "torch.Tensor([float('Inf')]) > torch.Tensor([float('NaN')])\n",
    "torch.Tensor([float('NaN')]) - torch.Tensor([float('NaN')])\n",
    "torch.Tensor([float('NaN')]) in set([torch.Tensor([float('NaN')])])\n",
    "0.3 == 3 * 0.1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([nan])\n",
      "tensor([False])\n",
      "tensor([False])\n",
      "tensor([nan])\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(0 * torch.Tensor([float('NaN')]))\n",
    "print(torch.Tensor([float('NaN')]) == torch.Tensor([float('NaN')]))\n",
    "print(torch.Tensor([float('Inf')]) > torch.Tensor([float('NaN')]))\n",
    "print(torch.Tensor([float('NaN')]) - torch.Tensor([float('NaN')]))\n",
    "print(torch.Tensor([float('NaN')]) in set([torch.Tensor([float('NaN')])]))\n",
    "print(0.3 == 3 * 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 18. 创建一个 5x5 的矩阵，对角线正下方元素是 1,2,3,4 (★☆☆)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 2., 0., 0., 0.],\n",
       "        [0., 0., 3., 0., 0.],\n",
       "        [0., 0., 0., 4., 0.]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "below_diagonal = torch.Tensor([1,2,3,4])\n",
    "torch.diag(below_diagonal, diagonal=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 19. 创建一个 8x8 矩阵，元素值为 0，1 交替出现（类似国际象棋棋盘样式，黑色对应 0，白色对应 1） (★☆☆)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 0, 1, 0, 1, 0, 1],\n",
      "        [1, 0, 1, 0, 1, 0, 1, 0],\n",
      "        [0, 1, 0, 1, 0, 1, 0, 1],\n",
      "        [1, 0, 1, 0, 1, 0, 1, 0],\n",
      "        [0, 1, 0, 1, 0, 1, 0, 1],\n",
      "        [1, 0, 1, 0, 1, 0, 1, 0],\n",
      "        [0, 1, 0, 1, 0, 1, 0, 1],\n",
      "        [1, 0, 1, 0, 1, 0, 1, 0]])\n"
     ]
    }
   ],
   "source": [
    "t = torch.zeros((8,8),dtype=int)\n",
    "t[1::2,::2] = 1\n",
    "t[::2,1::2] = 1\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 20. 一个尺寸为 (6,7,8) 的 Tensor，第 100 个元素的索引（index）是多少？返回的答案应符合 (x,y,z) 格式。\n",
    "提示：原问题答案使用了 numpy 中的 unravel_index 函数。PyTorch 中暂时没有对应函数，所以需要自己写代码计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5, 3)\n"
     ]
    }
   ],
   "source": [
    "# 这个函数来自 https://discuss.pytorch.org/t/how-to-do-a-unravel-index-in-pytorch-just-like-in-numpy/12987/3\n",
    "def unravel_index(index, shape):\n",
    "    out = []\n",
    "    for dim in reversed(shape):\n",
    "        out.append(index % dim)\n",
    "        index = index // dim\n",
    "    return tuple(reversed(out))\n",
    "\n",
    "print(unravel_index(99,(6,7,8)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 21. 使用 repeat 函数创建一个 8\\*8 矩阵，元素值为 0，1 交替出现（类似国际象棋棋盘样式，黑色对应 0，白色对应 1）  (★☆☆)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0., 1., 0., 1., 0., 1.],\n",
       "        [1., 0., 1., 0., 1., 0., 1., 0.],\n",
       "        [0., 1., 0., 1., 0., 1., 0., 1.],\n",
       "        [1., 0., 1., 0., 1., 0., 1., 0.],\n",
       "        [0., 1., 0., 1., 0., 1., 0., 1.],\n",
       "        [1., 0., 1., 0., 1., 0., 1., 0.],\n",
       "        [0., 1., 0., 1., 0., 1., 0., 1.],\n",
       "        [1., 0., 1., 0., 1., 0., 1., 0.]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.Tensor([[0, 1],\n",
    "                  [1, 0]])\n",
    "t.repeat([4, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 22. 标准化（Normalize）一个 5x5 的随机矩阵 (★☆☆)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7410,  1.7085,  0.4172, -0.7988, -0.3194],\n",
       "        [-1.1070, -0.3586,  1.3849, -1.1555, -0.4769],\n",
       "        [ 0.9504, -1.4502,  1.2538,  0.1464, -1.2049],\n",
       "        [-0.0923,  0.1852, -0.6042,  1.3192,  0.8722],\n",
       "        [ 1.3516, -1.1981,  1.1526, -1.1021, -0.1329]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.rand([5,5])\n",
    "(t - t.mean()) / t.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 23. 创建一个自定义数据结构，使用 4 个无符号字节定义颜色。\n",
    "原文：Create a custom dtype that describes a color as four unsigned bytes (RGBA)\n",
    "\n",
    "没太明白题目……"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 24. 将一个 5x3 矩阵乘以一个 3x2 矩阵(★☆☆)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3.],\n",
       "        [3., 3.],\n",
       "        [3., 3.],\n",
       "        [3., 3.],\n",
       "        [3., 3.]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones([5,3])\n",
    "b = torch.ones([3,2])\n",
    "torch.mm(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 25. 给定一个一维 Tensor，将其中值在 3-8 之间（不包含 3 和 8）的元素取负（不创建新 Tensor） (★☆☆)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3, -4, -5, -6, -7,  8,  9])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.arange(10)\n",
    "t[(3<t) & (t<8)] *= -1\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 26.以下代码的输出值是什么？ (★☆☆)\n",
    "```python\n",
    "# 作者: Jake VanderPlas\n",
    "\n",
    "print(sum(range(5),-1))\n",
    "from torch import *\n",
    "print(sum(range(5),-1))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "tensor(10)\n"
     ]
    }
   ],
   "source": [
    "print(sum(range(5),-1))\n",
    "def test():\n",
    "    from torch import sum\n",
    "    print(sum(torch.arange(5), -1))\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 27. 给定一个整数向量 Z, 以下哪些式子是合法的? (★☆☆)\n",
    "```python\n",
    "Z**Z\n",
    "2 << Z >> 2\n",
    "Z <- Z\n",
    "1j*Z\n",
    "Z/1/1\n",
    "Z<Z>Z\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2], dtype=torch.int32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 被注释掉的都不合法\n",
    "Z = torch.Tensor([1, 2]).type(torch.int)\n",
    "\n",
    "\n",
    "Z**Z\n",
    "# 2 << Z >> 2\n",
    "Z <- Z\n",
    "1j*Z\n",
    "Z/1/1\n",
    "# Z<Z>Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 28. 以下表达式的计算结果分别是什么?\n",
    "```python\n",
    "torch.Tensor(0) / torch.Tensor(0)\n",
    "torch.Tensor(0) // torch.Tensor(0)\n",
    "torch.Tensor([float('NaN')]).type(torch.int).type(torch.float)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([])\n",
      "tensor([])\n",
      "tensor([-2.1475e+09])\n"
     ]
    }
   ],
   "source": [
    "print(torch.Tensor(0) / torch.Tensor(0))\n",
    "print(torch.Tensor(0) // torch.Tensor(0))\n",
    "print(torch.Tensor([float('NaN')]).type(torch.int).type(torch.float))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 29. 将 float 类型的 Tensor 中元素进位转换为整数 (★☆☆)\n",
    "译者注：这里的 \"进位\" 原文是 round away from zero，即 3.2 => 4，-3.2=> -4。可参考 https://en.wikipedia.org/wiki/Rounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.4683, -4.8236, -5.8396],\n",
      "        [-0.4007, -2.2996, -0.9277]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-2., -5., -6.],\n",
       "        [-1., -3., -1.]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.randn([2,3]) * 3\n",
    "print(t)\n",
    "\n",
    "torch.mul(torch.sign(t), torch.ceil(torch.abs(t)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 30. 找出两个一维 Tensor 中都出现的元素 (★☆☆)\n",
    "译者注：numpy 可以使用 `intersect1d` 函数，但 PyTorch 暂无对应函数。简单的处理方法就是转成 numpy array 后使用 intersect1d。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3 1 1 0 6 0 4 5 3]\n",
      "[1 7 2 3 5 4 5 8 0 1]\n",
      "[0 1 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "# 原题答案\n",
    "import numpy as np\n",
    "Z1 = np.random.randint(0,10,10)\n",
    "Z2 = np.random.randint(0,10,10)\n",
    "print(Z1)\n",
    "print(Z2)\n",
    "print(np.intersect1d(Z1,Z2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 31. 如何忽略所有的 PyTorch 警告（warnings） (不建议这么做)? (★☆☆)\n",
    "译者注：numpy 可直接使用 seterr 方法忽略警告，但是 PyTorch 没有内置的相关设置。但是 PyTorch 的所有警告都是使用了 Python 中内置的 warnings，因此可以直接使用 Python 对 warnings 的操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 32. 以下表达式的值为真吗？ (★☆☆)\n",
    "```python\n",
    "np.sqrt(-1) == np.emath.sqrt(-1)\n",
    "```\n",
    "\n",
    "PyTorch 中没有对应 Numpy 的 emath 的模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(-1) == np.emath.sqrt(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 33. 如何获取昨天、今天、明天的日期？ (★☆☆)\n",
    "译者注：PyTorch 中没有关于日期的模块。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "yesterday = np.datetime64('today', 'D') - np.timedelta64(1, 'D')\n",
    "today     = np.datetime64('today', 'D')\n",
    "tomorrow  = np.datetime64('today', 'D') + np.timedelta64(1, 'D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 34. 如何获取 2016 年 7 月的每一天日期? (★★☆)\n",
    "译者注：PyTorch 中没有关于日期的模块。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2016-07-01' '2016-07-02' '2016-07-03' '2016-07-04' '2016-07-05'\n",
      " '2016-07-06' '2016-07-07' '2016-07-08' '2016-07-09' '2016-07-10'\n",
      " '2016-07-11' '2016-07-12' '2016-07-13' '2016-07-14' '2016-07-15'\n",
      " '2016-07-16' '2016-07-17' '2016-07-18' '2016-07-19' '2016-07-20'\n",
      " '2016-07-21' '2016-07-22' '2016-07-23' '2016-07-24' '2016-07-25'\n",
      " '2016-07-26' '2016-07-27' '2016-07-28' '2016-07-29' '2016-07-30'\n",
      " '2016-07-31']\n"
     ]
    }
   ],
   "source": [
    "Z = np.arange('2016-07', '2016-08', dtype='datetime64[D]')\n",
    "print(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 35. 在不复制值的情况下做原地计算 ((A+B)*(-A/2))(★★☆)\n",
    "译者注：计算过程中的值只能保存在 A/B 中，不能创建新的 Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.5000, -1.5000, -1.5000])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.ones(3)*1\n",
    "B = torch.ones(3)*2\n",
    "torch.add(A, B, out=B)\n",
    "torch.div(A, 2, out=A)\n",
    "torch.neg_(A)\n",
    "torch.mul(A, B, out=B)\n",
    "B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 36. 用 5 种不同的方法提取随机 Tensor 中每个元素的整数部分 (★★☆)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.6824, 3.8952],\n",
      "        [4.7558, 0.3342]])\n",
      "tensor([[3., 3.],\n",
      "        [4., 0.]])\n",
      "tensor([[3., 3.],\n",
      "        [4., 0.]])\n",
      "tensor([[3., 3.],\n",
      "        [4., 0.]])\n",
      "tensor([[3, 3],\n",
      "        [4, 0]], dtype=torch.int32)\n",
      "tensor([[3., 3.],\n",
      "        [4., 0.]])\n"
     ]
    }
   ],
   "source": [
    "Z = torch.rand([2,2]) * 5\n",
    "print(Z)\n",
    "\n",
    "\n",
    "print(Z - Z%1)\n",
    "print(torch.floor(Z))\n",
    "print(torch.ceil(Z)-1)\n",
    "print(Z.type(torch.int))\n",
    "print(torch.trunc(Z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 37. 创建一个 5x5 矩阵，每一行的值是 0-4(★★☆)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3, 4],\n",
       "        [0, 1, 2, 3, 4],\n",
       "        [0, 1, 2, 3, 4],\n",
       "        [0, 1, 2, 3, 4],\n",
       "        [0, 1, 2, 3, 4]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(5).repeat([5,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 38. 创建一个生成器函数，用于生成 10 个整数，并用这个生成器函数创建一个一维 Tensor(★☆☆)\n",
    "译者注:numpy 支持从生成器中创建 array，但 PyTorch 不支持。可以先将这个生成器转换成 numpy array，再转换为 PyTorch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def g():\n",
    "    yield from range(10)\n",
    "torch.from_numpy(np.fromiter(g(), dtype=np.int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 39. 创建一个长度为 10 的向量，每个元素的值在 0-1 之间（不包括 0 和 1）(★★☆)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0909, 0.1818, 0.2727, 0.3636, 0.4545, 0.5455, 0.6364, 0.7273, 0.8182,\n",
       "        0.9091])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linspace(0, 1, steps=12)[1:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 40. 创建一个长度为 10 的随机向量，并排序(★★☆)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.sort(values=tensor([0.2024, 0.2088, 0.2191, 0.3271, 0.3837, 0.5384, 0.6871, 0.8495, 0.8641,\n",
       "        0.8957]), indices=tensor([8, 2, 4, 9, 1, 6, 5, 0, 3, 7]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sort(torch.rand([10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 41. 对一个小向量求和时，如何计算才能比使用 np.sum 更快？(★★☆)\n",
    "译者注：在 numpy 中，可以使用 `np.add.reduce`，在小向量上计算速度快于`np.sum`。但 PyTorch 似乎没有对应的方法，经测试，对 `torch.arange(10)` 进行求和时，torch.sum 仍然快于 np.add.reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 原题答案\n",
    "Z = np.arange(10)\n",
    "np.add.reduce(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 42. 给定两个随机 Tensor A 和 B，判断是否相等 (★★☆)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# 检查值是否精确相等\n",
    "print(torch.equal(torch.Tensor([1.1, 2.1]), torch.Tensor([1, 2])))\n",
    "\n",
    "# 检查值相等时允许一定误差\n",
    "print(torch.allclose(torch.Tensor([1.1, 2.1]), torch.Tensor([1, 2]), atol=0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 43. 将 Tensor 转变为只读(★★☆)\n",
    "译者注：numpy 可以对数组定义 writeable 属性，但 PyTorch 貌似不支持"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 原题答案\n",
    "Z = np.zeros(10)\n",
    "Z.flags.writeable = False\n",
    "# Z[0] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 44. 一个随机 10x2 矩阵，每一行表示一个笛卡尔坐标，将其转换为对应的极坐标值 (★★☆)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0625, 1.0960],\n",
       "        [1.1245, 0.7912],\n",
       "        [0.8325, 0.0044],\n",
       "        [1.0051, 0.8870],\n",
       "        [1.3247, 0.8002],\n",
       "        [0.6153, 0.6570],\n",
       "        [0.6864, 0.4895],\n",
       "        [0.8644, 1.4203],\n",
       "        [0.4298, 1.3370],\n",
       "        [0.8034, 0.8322]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.rand([10, 2])\n",
    "X = t[:,0]\n",
    "Y = t[:,1]\n",
    "R = torch.sqrt(X**2+Y**2)\n",
    "T = torch.atan(Y/X)\n",
    "torch.stack([R,T], dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 45. 创建一个长度为 10 的随机向量，将其中最大值替换为 0(★★☆)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3938, 0.2359, 0.2153, 0.0000, 0.1971, 0.0092, 0.7057, 0.2028, 0.5011,\n",
       "        0.1906])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.rand(10)\n",
    "t[torch.argmax(t)] = 0\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 46. 在直角坐标轴上 (0,0) 到 (1,1) 区域内放一个 5x5 的网格，创建一个5x5x2 的 Tensor，其值对应网格中每个点的坐标(★★☆)\n",
    "译者注：原题要求使用 numpy 的 structured array 这个数据结构，PyTorch 疑似没有。故略微修改了题目。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0000],\n",
       "         [0.0000, 0.2500],\n",
       "         [0.0000, 0.5000],\n",
       "         [0.0000, 0.7500],\n",
       "         [0.0000, 1.0000]],\n",
       "\n",
       "        [[0.2500, 0.0000],\n",
       "         [0.2500, 0.2500],\n",
       "         [0.2500, 0.5000],\n",
       "         [0.2500, 0.7500],\n",
       "         [0.2500, 1.0000]],\n",
       "\n",
       "        [[0.5000, 0.0000],\n",
       "         [0.5000, 0.2500],\n",
       "         [0.5000, 0.5000],\n",
       "         [0.5000, 0.7500],\n",
       "         [0.5000, 1.0000]],\n",
       "\n",
       "        [[0.7500, 0.0000],\n",
       "         [0.7500, 0.2500],\n",
       "         [0.7500, 0.5000],\n",
       "         [0.7500, 0.7500],\n",
       "         [0.7500, 1.0000]],\n",
       "\n",
       "        [[1.0000, 0.0000],\n",
       "         [1.0000, 0.2500],\n",
       "         [1.0000, 0.5000],\n",
       "         [1.0000, 0.7500],\n",
       "         [1.0000, 1.0000]]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,Y = torch.meshgrid(torch.linspace(0,1,5),\n",
    "                     torch.linspace(0,1,5))\n",
    "torch.stack([X,Y], dim=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 47. 给定两个向量 X,Y，创建一个柯西矩阵 C（Cij =1/(xi - yj)）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3333, -0.1429, -0.0909, -0.0714],\n",
       "        [-0.5000, -0.1667, -0.1000, -0.0769],\n",
       "        [-1.0000, -0.2000, -0.1111, -0.0833]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.Tensor([1,2,3])\n",
    "y = torch.Tensor([4,8,12, 15])\n",
    "torch.div(1, x.view([-1,1]) - y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 48. 打印 PyTorch Tensor 每一种标量数据结构的最大和最小可表示数（representable value）(★★☆)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-128\n",
      "127\n",
      "-2147483648\n",
      "2147483647\n",
      "-9223372036854775808\n",
      "9223372036854775807\n",
      "-3.4028234663852886e+38\n",
      "3.4028234663852886e+38\n",
      "1.1920928955078125e-07\n",
      "-1.7976931348623157e+308\n",
      "1.7976931348623157e+308\n",
      "2.220446049250313e-16\n"
     ]
    }
   ],
   "source": [
    "for dtype in [torch.int8, torch.int32, torch.int64]:\n",
    "    print(torch.iinfo(dtype).min)\n",
    "    print(torch.iinfo(dtype).max)\n",
    "for dtype in [torch.float32, torch.float64]:\n",
    "    print(torch.finfo(dtype).min)\n",
    "    print(torch.finfo(dtype).max)\n",
    "    print(torch.finfo(dtype).eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 49. 如何完整显示 Tensor 的所有值? (★★☆)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(threshold=float('NaN'))\n",
    "Z = torch.zeros((16,16))\n",
    "print(Z)\n",
    "\n",
    "# 恢复默认打印设置\n",
    "torch.set_printoptions(threshold=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 50. 给定一个标量和一个向量，找出向量中与给定标量值最接近的元素(★★☆)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9369, 0.9029, 0.7763, 0.7393, 0.7171])\n",
      "tensor(0.7171)\n"
     ]
    }
   ],
   "source": [
    "t = torch.rand([5])\n",
    "print(t)\n",
    "scalar = 0.123\n",
    "i = torch.abs(t-scalar).argmin()\n",
    "print(t[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 51. Create a structured array representing a position (x,y) and a color (r,g,b) (★★☆)\n",
    "译者注：又要使用 Numpy 中的 structured array。PyTorch 似乎没有对应数据结构。跳过本题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 52. 给定一个 (100,2) 的矩阵，每行表示一个点的坐标。计算所有点两两之间距离。(★★☆)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.1477, 0.3086,  ..., 0.6090, 0.4416, 0.6262],\n",
      "        [0.1477, 0.0000, 0.1733,  ..., 0.6905, 0.4497, 0.7396],\n",
      "        [0.3086, 0.1733, 0.0000,  ..., 0.8560, 0.4249, 0.9125],\n",
      "        ...,\n",
      "        [0.6090, 0.6905, 0.8560,  ..., 0.0000, 1.0326, 0.1950],\n",
      "        [0.4416, 0.4497, 0.4249,  ..., 1.0326, 0.0000, 1.0067],\n",
      "        [0.6262, 0.7396, 0.9125,  ..., 0.1950, 1.0067, 0.0000]])\n",
      "[[0.         0.14769054 0.30863713 ... 0.60896666 0.44158527 0.62620633]\n",
      " [0.14769054 0.         0.17327868 ... 0.69051978 0.44965802 0.73958197]\n",
      " [0.30863713 0.17327868 0.         ... 0.85603198 0.42492931 0.91250794]\n",
      " ...\n",
      " [0.60896666 0.69051978 0.85603198 ... 0.         1.03264791 0.19495208]\n",
      " [0.44158527 0.44965802 0.42492931 ... 1.03264791 0.         1.00674365]\n",
      " [0.62620633 0.73958197 0.91250794 ... 0.19495208 1.00674365 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# 答案一\n",
    "t = torch.rand([100,2])\n",
    "X = t[:,0].view([1,-1])\n",
    "Y = t[:,1].view([1,-1])\n",
    "print(torch.sqrt((X-X.T)**2 + (Y-Y.T)**2))\n",
    "\n",
    "\n",
    "# 答案二（使用 scipy，快很多）\n",
    "# 感谢 Gavin Heverly-Coulson\n",
    "import scipy\n",
    "import scipy.spatial\n",
    "\n",
    "D = scipy.spatial.distance.cdist(t,t)\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 53. 原地将一个浮点型 (32 bits) Tensor 转换为整型（32 bits）?\n",
    "译者注：原题使用了 Numpy 的 `view` 方法，该方法与 PyTorch Tensor 中的 `view` 作用并不相同。以下为原题答案。暂未找到 PyTorch 如何处理这个问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5 37 38 85 29 71 53 58  2  2]\n"
     ]
    }
   ],
   "source": [
    "# Thanks Vikas (https://stackoverflow.com/a/10622758/5989906)\n",
    "# & unutbu (https://stackoverflow.com/a/4396247/5989906)\n",
    "Z = (np.random.rand(10)*100).astype(np.float32)\n",
    "Y = Z.view(np.int32)\n",
    "Y[:] = Z\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 54. 将以下内容的 Tensor 保存至硬盘，并再次读取(★★☆)\n",
    "```\n",
    "1, 2, 3, 4, 5\n",
    "6, 0, 0, 7, 8\n",
    "0, 0, 9,10,11\n",
    "```\n",
    "译者注：原题是问“如果读取以下内容的文件”，使用了 numpy 的 `genfromtxt` 方法。由于 PyTorch 不支持从纯文本读取 Tensor，故略微修改了题目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.,  4.,  5.],\n",
       "        [ 6.,  0.,  0.,  7.,  8.],\n",
       "        [ 0.,  0.,  9., 10., 11.]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.Tensor([[1, 2, 3, 4, 5],\n",
    "                 [6, 0, 0, 7, 8],\n",
    "                 [0, 0, 9,10,11]])\n",
    "torch.save(t, '/Users/Desktop/tensors.pt')\n",
    "s = torch.load('/Users/Desktop/tensors.pt')\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 55. `enumerate` 函数在 PyTorch 中对应的函数是什么？(★★☆)\n",
    "译者注：原题是问 numpy 中的对应函数，即 `ndenumerate`。但 PyTorch 中好像没有"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0) 0\n",
      "(0, 1) 1\n",
      "(0, 2) 2\n",
      "(1, 0) 3\n",
      "(1, 1) 4\n",
      "(1, 2) 5\n",
      "(2, 0) 6\n",
      "(2, 1) 7\n",
      "(2, 2) 8\n"
     ]
    }
   ],
   "source": [
    "# 原题答案\n",
    "Z = np.arange(9).reshape(3,3)\n",
    "for index, value in np.ndenumerate(Z):\n",
    "print(index, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 56. Generate a generic 2D Gaussian-like array (★★☆)\n",
    "译者注：这是啥玩意？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.36787944 0.44822088 0.51979489 0.57375342 0.60279818 0.60279818\n",
      "  0.57375342 0.51979489 0.44822088 0.36787944]\n",
      " [0.44822088 0.54610814 0.63331324 0.69905581 0.73444367 0.73444367\n",
      "  0.69905581 0.63331324 0.54610814 0.44822088]\n",
      " [0.51979489 0.63331324 0.73444367 0.81068432 0.85172308 0.85172308\n",
      "  0.81068432 0.73444367 0.63331324 0.51979489]\n",
      " [0.57375342 0.69905581 0.81068432 0.89483932 0.9401382  0.9401382\n",
      "  0.89483932 0.81068432 0.69905581 0.57375342]\n",
      " [0.60279818 0.73444367 0.85172308 0.9401382  0.98773022 0.98773022\n",
      "  0.9401382  0.85172308 0.73444367 0.60279818]\n",
      " [0.60279818 0.73444367 0.85172308 0.9401382  0.98773022 0.98773022\n",
      "  0.9401382  0.85172308 0.73444367 0.60279818]\n",
      " [0.57375342 0.69905581 0.81068432 0.89483932 0.9401382  0.9401382\n",
      "  0.89483932 0.81068432 0.69905581 0.57375342]\n",
      " [0.51979489 0.63331324 0.73444367 0.81068432 0.85172308 0.85172308\n",
      "  0.81068432 0.73444367 0.63331324 0.51979489]\n",
      " [0.44822088 0.54610814 0.63331324 0.69905581 0.73444367 0.73444367\n",
      "  0.69905581 0.63331324 0.54610814 0.44822088]\n",
      " [0.36787944 0.44822088 0.51979489 0.57375342 0.60279818 0.60279818\n",
      "  0.57375342 0.51979489 0.44822088 0.36787944]]\n"
     ]
    }
   ],
   "source": [
    "# 原题答案\n",
    "X, Y = np.meshgrid(np.linspace(-1,1,10), np.linspace(-1,1,10))\n",
    "D = np.sqrt(X*X+Y*Y)\n",
    "sigma, mu = 1.0, 0.0\n",
    "G = np.exp(-( (D-mu)**2 / ( 2.0 * sigma**2 ) ) )\n",
    "print(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 57. 一个矩阵中随机选 p 个元素，并替换成其他值(★★☆)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.7138, 0.0000],\n",
       "        [0.0000, 0.0000, 0.7391],\n",
       "        [0.0000, 0.9552, 0.0000]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = 3\n",
    "t = torch.zeros([3,3])\n",
    "indices = torch.from_numpy(np.random.choice(range(9), p))\n",
    "t.put_(indices, torch.rand(p), accumulate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 58. 给定一个矩阵，计算每个元素减去所在行的平均数(★★☆)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2., -1.,  0.,  1.,  2.],\n",
       "        [-2., -1.,  0.,  1.,  2.]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(10).view([2,5]).type(torch.float32)\n",
    "Y = X - X.mean(axis=1, keepdims=True)\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 59. 给定一个矩阵，根据第 n 列的值对行排序(★★☆)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[8, 4, 3],\n",
      "        [8, 6, 1],\n",
      "        [1, 4, 8]])\n",
      "tensor([[8, 4, 3],\n",
      "        [1, 4, 8],\n",
      "        [8, 6, 1]])\n"
     ]
    }
   ],
   "source": [
    "t = torch.randint(0,10,(3,3))\n",
    "n = 1\n",
    "print(t)\n",
    "print(t[t[:,1].argsort()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 60. 给定一个矩阵，判断是否存在值全为 0 的列(★★☆)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 0, 0, 0, 0, 2, 1, 2, 0, 2],\n",
      "        [0, 1, 0, 1, 2, 1, 0, 0, 0, 1],\n",
      "        [1, 1, 2, 2, 2, 0, 1, 2, 0, 1]])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "t = torch.randint(0,3,(3,10))\n",
    "print(t)\n",
    "print((t==0).all(dim=0).any().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 61. 题同 50.(★★☆)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 62. 给定两个矩阵，尺寸分别为 (1,3) 和 (3,1)。计算两个矩阵元素两两之和，得到一个 (3,3) 矩阵(★★☆)\n",
    "译者注：根据题目答案，修改了题目表述。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [1, 2, 3],\n",
       "        [2, 3, 4]])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(3).view([3,1])\n",
    "B = torch.arange(3).view([1,3])\n",
    "A + B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 63. 创建一个继承自 PyTorch.Tensor 的类，并赋予其 name_ 属性 (★★☆)\n",
    "答案参考：https://discuss.pytorch.org/t/subclassing-torch-tensor/23754/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'some_name'"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NamedTensor(torch.Tensor):\n",
    "    @staticmethod\n",
    "    def __new__(cls, x, name, *args, **kwargs):\n",
    "        obj = super().__new__(cls, x, *args, **kwargs)\n",
    "        obj.name_ = name\n",
    "        return obj\n",
    "\n",
    "Z = NamedTensor(torch.rand([3,3]), \"some_name\")\n",
    "Z.name_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 64. 给定一个向量 A，另一个向量 B 中的值为 A 的元素索引。将 B 中索引对应的 A 的元素加 1。（注意 B 中可能有重复的索引，重复几次就要加几次 1）(★★★)\n",
    "译者注：例如 `A=[1, 1, 1]`, `B=[1,2,2,2]`,则最终的效果是得到向量 `[1,2,4]`，A 中的第一个元素（从 0 开始计数元素）加了一次 1，第二个元素加了 3 次 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 4.])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.Tensor([1,1,1])\n",
    "B = torch.Tensor([1,2,2,2]).type(torch.int64)\n",
    "A.index_add(0, B, torch.ones([B.shape[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 65. 去研究下 torch.bincount 函数\n",
    "译者注：原问题的表述真的很难懂，实际上就是用了个 `bincount` 函数。这个函数用法不难，但是三言两语很难说清楚。大家看文档吧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 7., 0., 6., 5., 0., 0., 0., 0., 3.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "X = torch.Tensor([1,2,3,4,5,6]).type(torch.int64)\n",
    "I = torch.Tensor([1,3,9,3,4,1]).type(torch.int64)\n",
    "F = torch.bincount(I,X)\n",
    "print(F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 66. 给定一个尺寸为 (w,h,3) 的图像，计算图像中有多少种不重复的颜色(★★★)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w,h = 16,16\n",
    "I = torch.randint(0,256,(h,w,3)).type(torch.int8)\n",
    "F = I[...,0]*256*256 + I[...,1]*256 +I[...,2]\n",
    "n = len(torch.unique(F))\n",
    "n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 67. 给定一个四维 Tensor，如何计算最后两维的和(★★★)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[49, 44, 47, 61],\n",
       "        [51, 64, 68, 78],\n",
       "        [35, 49, 62, 51]])"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.randint(0,10,(3,4,3,4))\n",
    "A.sum(axis=(-2,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 68. 给定向量 D 以及另一个同长度向量 S。计算 S 中所有值相同元素对应的同位置 D 中的元素的平均数(★★★)\n",
    "译者注：例如 `D=[1, 1, 0, 1, 0]`, `S=[2, 0, 3, 2, 2]`\n",
    "\n",
    "S 中值为 `2` 的 3 个元素所在位置对应的 D 中同位置元素是 `[1,1,0]`，平均数是 $2/3$；\n",
    "\n",
    "同理， S 中值为 `0` 的 1 个元素所在位置对应的 D 中同位置元素是 `[1]`，平均数就是 1\n",
    "\n",
    "同理， S 中值为 `3` 的 1 个元素所在位置对应的 D 中同位置元素是 `[0]`，平均数就是 0\n",
    "\n",
    "最终的输出就是 `[1, 2/3， 0]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5796, 0.6110, 0.5940, 0.6478, 0.3952, 0.5396, 0.5413, 0.6328, 0.4466,\n",
      "        0.5895])\n",
      "0    0.579558\n",
      "1    0.611022\n",
      "2    0.594034\n",
      "3    0.647782\n",
      "4    0.395194\n",
      "5    0.539622\n",
      "6    0.541287\n",
      "7    0.632786\n",
      "8    0.446596\n",
      "9    0.589531\n",
      "dtype: float32\n"
     ]
    }
   ],
   "source": [
    "# 作者: Jaime Fernández del Río\n",
    "D = torch.rand([100])\n",
    "S = torch.randint(0,10,[100])\n",
    "D_sums = torch.bincount(S, weights=D)\n",
    "D_counts = torch.bincount(S)\n",
    "D_means = D_sums / D_counts\n",
    "print(D_means)\n",
    "\n",
    "# 也可以使用 Pandas\n",
    "import pandas as pd\n",
    "print(pd.Series(D.numpy()).groupby(S.numpy()).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 69. 如何获取两个矩阵相乘的结果的对角线元素? (★★★)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2, 11])\n",
      "tensor([ 2, 11])\n",
      "tensor([ 2, 11])\n"
     ]
    }
   ],
   "source": [
    "A = torch.arange(4).view([2,2])\n",
    "B = torch.arange(4).view([2,2])\n",
    "\n",
    "# 答案一\n",
    "print(torch.diagonal(torch.mm(A,B)))\n",
    "\n",
    "# 答案二\n",
    "print(torch.sum(A * B.T, axis=1))\n",
    "\n",
    "# 答案三\n",
    "print(torch.einsum(\"ij,ji->i\", A, B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 70. 给定向量 `[1, 2, 3, 4, 5]`，所有元素之间插入 3 个 0，得到新向量 `[1, 0, 0, 0, 2, 0, 0, 0, 3, 0, 0, 0, 4, 0, 0, 0, 5]`(★★★)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 0., 0., 2., 0., 0., 0., 3., 0., 0., 0., 4., 0., 0., 0., 5.])"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.Tensor([1,2,3,4,5])\n",
    "t0 = torch.zeros([len(Z) + (len(Z)-1)*3])\n",
    "t0[::4] = t\n",
    "t0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 71. 给定一个尺寸为 (5,5,3) 的 Tensor，如何将它和一个尺寸为 (5,5) 的 Tensor 相乘? (★★★)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2., 2., 2.],\n",
       "         [2., 2., 2.],\n",
       "         [2., 2., 2.],\n",
       "         [2., 2., 2.],\n",
       "         [2., 2., 2.]],\n",
       "\n",
       "        [[2., 2., 2.],\n",
       "         [2., 2., 2.],\n",
       "         [2., 2., 2.],\n",
       "         [2., 2., 2.],\n",
       "         [2., 2., 2.]],\n",
       "\n",
       "        [[2., 2., 2.],\n",
       "         [2., 2., 2.],\n",
       "         [2., 2., 2.],\n",
       "         [2., 2., 2.],\n",
       "         [2., 2., 2.]],\n",
       "\n",
       "        [[2., 2., 2.],\n",
       "         [2., 2., 2.],\n",
       "         [2., 2., 2.],\n",
       "         [2., 2., 2.],\n",
       "         [2., 2., 2.]],\n",
       "\n",
       "        [[2., 2., 2.],\n",
       "         [2., 2., 2.],\n",
       "         [2., 2., 2.],\n",
       "         [2., 2., 2.],\n",
       "         [2., 2., 2.]]])"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.ones((5,5,3))\n",
    "B = 2*torch.ones((5,5))\n",
    "A * B[:,:,None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 72. 交换一个 Tensor 内两行的位置? (★★★)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5,  6,  7,  8,  9],\n",
      "        [ 0,  1,  2,  3,  4],\n",
      "        [10, 11, 12, 13, 14],\n",
      "        [15, 16, 17, 18, 19],\n",
      "        [20, 21, 22, 23, 24]])\n"
     ]
    }
   ],
   "source": [
    "# 作者: Eelco Hoogendoorn\n",
    "A =  torch.arange(25).view(5,5)\n",
    "A[[0,1]] = A[[1,0]]\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 73. Consider a set of 10 triplets describing 10 triangles (with shared vertices), find the set of unique line segments composing all the  triangles (★★★)\n",
    "译者注：看不懂题目到底想干啥……答案给的示例中，有些数据都无法组成三角形（不满足两边之长必须大于第三边）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[( 6, 19) ( 6, 54) (15, 20) (15, 31) (19, 32) (19, 54) (19, 71) (20, 31)\n",
      " (21, 47) (21, 77) (24, 55) (24, 64) (28, 31) (28, 78) (31, 38) (31, 76)\n",
      " (31, 78) (32, 71) (37, 68) (37, 90) (38, 76) (44, 49) (44, 73) (47, 53)\n",
      " (47, 77) (47, 79) (49, 73) (53, 79) (55, 64) (68, 90)]\n"
     ]
    }
   ],
   "source": [
    "# 原题答案\n",
    "faces = np.random.randint(0,100,(10,3))\n",
    "F = np.roll(faces.repeat(2,axis=1),-1,axis=1)\n",
    "F = F.reshape(len(F)*3,2)\n",
    "F = np.sort(F,axis=1)\n",
    "G = F.view( dtype=[('p0',F.dtype),('p1',F.dtype)] )\n",
    "G = np.unique(G)\n",
    "print(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 74. 给定向量 C 是 `bincount` 函数的运行结果，如何计算出向量 A，使得 `torch.bincount(A) == C`?(★★★)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 2, 3, 4, 4, 6])\n"
     ]
    }
   ],
   "source": [
    "# 作者: Jaime Fernández del Río\n",
    "t = torch.Tensor([1,1,2,3,4,4,6]).type(torch.int64)\n",
    "C =  torch.bincount(t)\n",
    "T = torch.repeat_interleave(torch.arange(len(C)), C)\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 75. 计算一个一维 Tensor 每个滑动窗口（sliding window）内的平均数 (★★★)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18])\n"
     ]
    }
   ],
   "source": [
    "# 作者: Jaime Fernández del Río\n",
    "def moving_average(a, n=3) :\n",
    "    ret = torch.cumsum(a, dim=0)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return ret[n - 1:] / n\n",
    "Z = torch.arange(20)\n",
    "print(moving_average(Z, n=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 76. 给定一个一维 Tensor Z，创建一个二维 Tensor，其第一行是 (Z[0],Z[1],Z[2])，其后的每一行是上一行再后延 1 位（第二行就是 (Z[1],Z[2],Z[3])，最后一行就是 (Z[-3],Z[-2],Z[-1])）(★★★)\n",
    "译者注：原题使用了 `numpy.lib` 中的 `stride_tricks.as_strided`。PyTorch 有对应函数 `torch.as_strided`但是用法似乎和 numpy 中的用法不太一样，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2]\n",
      " [1 2 3]\n",
      " [2 3 4]\n",
      " [3 4 5]\n",
      " [4 5 6]\n",
      " [5 6 7]\n",
      " [6 7 8]\n",
      " [7 8 9]]\n"
     ]
    }
   ],
   "source": [
    "# 原题答案\n",
    "# 作者: Joe Kington / Erik Rigtorp\n",
    "from numpy.lib import stride_tricks\n",
    "\n",
    "def rolling(a, window):\n",
    "    shape = (a.size - window + 1, window)\n",
    "    strides = (a.itemsize, a.itemsize)\n",
    "    return stride_tricks.as_strided(a, shape=shape, strides=strides)\n",
    "\n",
    "Z = rolling(np.arange(10), 3)\n",
    "print(Z)\n",
    "\n",
    "# 对应 PyTorch 版本，会报错\n",
    "# def rolling(a, window):\n",
    "#     shape = (a.size()[0] - window + 1, window)\n",
    "#     strides = (a.element_size(), a.element_size())\n",
    "#     return torch.as_strided(a, size=shape, stride=strides)\n",
    "# Z = rolling(torch.arange(10), 3)\n",
    "# print(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 77. 如何原地对布尔值取反，或改变浮点型数据的正负? (★★★)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2840, -0.8931, -0.5477, -0.7215, -0.2820, -0.9569, -0.9097, -0.9031,\n",
       "        -0.2542, -0.9451, -0.9212, -0.6158, -0.9553, -0.5441, -0.4852, -0.2866,\n",
       "        -0.3331, -0.6023, -0.8154, -0.6689, -0.4746, -0.1201, -0.8943, -0.9739,\n",
       "        -0.1949, -0.7605, -0.7338, -0.1762, -0.6662, -0.1584, -0.3059, -0.3109,\n",
       "        -0.0514, -0.4306, -0.9005, -0.9735, -0.3369, -0.0975, -0.8937, -0.4418,\n",
       "        -0.6114, -0.8907, -0.4427, -0.8724, -0.5632, -0.0595, -0.8335, -0.3437,\n",
       "        -0.4713, -0.8920, -0.4929, -0.6631, -0.8832, -0.1838, -0.7656, -0.4362,\n",
       "        -0.5145, -0.9621, -0.9753, -0.2228, -0.8827, -0.5216, -0.3937, -0.0318,\n",
       "        -0.9728, -0.4865, -0.0342, -0.0086, -0.6342, -0.9507, -0.6297, -0.2634,\n",
       "        -0.3199, -0.5835, -0.6927, -0.7704, -0.2197, -0.9681, -0.5293, -0.6745,\n",
       "        -0.0226, -0.6046, -0.9474, -0.8368, -0.0099, -0.4902, -0.7092, -0.8561,\n",
       "        -0.9838, -0.4841, -0.6651, -0.9477, -0.2883, -0.7081, -0.6784, -0.0863,\n",
       "        -0.7160, -0.3286, -0.2335, -0.9060])"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z = torch.randint(0,2,[100])\n",
    "torch.logical_not(Z, out=Z)\n",
    "\n",
    "Z = torch.rand([100])\n",
    "torch.neg(Z, out=Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 78. P0 和 P1 是两个矩阵，每个矩阵每一行对应一个点的坐标。给定点 p，计算 p 到每一条 (P0[i],P1[i]) 组成的线的距离(★★★)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2.1073,  4.5128,  8.9656, 10.6194,  5.6808,  4.5276,  4.4780,  4.6085,\n",
      "         8.6444,  8.9815])\n"
     ]
    }
   ],
   "source": [
    "def distance(P0, P1, p):\n",
    "    T = P1 - P0\n",
    "    L = (T**2).sum(axis=1)\n",
    "    U = -((P0[:,0]-p[...,0])*T[:,0] + (P0[:,1]-p[...,1])*T[:,1]) / L\n",
    "    U = U.reshape([len(U),1])\n",
    "    D = P0 + U*T - p\n",
    "    return torch.sqrt((D**2).sum(axis=1))\n",
    "\n",
    "\n",
    "P0 = (torch.rand([10,2])-0.5) * 20\n",
    "P1 = (torch.rand([10,2])-0.5) * 20\n",
    "p = (torch.rand([1,2])-0.5) * 20\n",
    "print(distance(P0, P1, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 79. P0， P1 和 P 是三个矩阵，每个矩阵每一行对应一个点的坐标。计算 P 中每一个点到每一条 (P0[i],P1[i]) 组成的线的距离(★★★) (★★★)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[12.2779,  1.3336,  5.9773,  3.7629,  0.8507, 10.8187,  9.2593,  5.2411,\n",
      "          9.8643, 10.8570],\n",
      "        [ 0.9368,  0.6516,  5.8760,  3.3524,  0.9357, 13.7890, 10.2336,  1.3867,\n",
      "          7.0634,  2.1478],\n",
      "        [ 7.2894,  2.5639,  2.5726,  1.6594,  1.0776,  9.9672,  7.6524,  2.0011,\n",
      "          6.9566,  6.2781],\n",
      "        [ 9.7857,  2.2749,  0.6442,  6.5725,  3.8338, 14.7259, 12.5430,  6.7235,\n",
      "         11.7759,  6.2779],\n",
      "        [ 3.2030,  3.7205,  6.4881,  6.6023,  4.1572, 16.7508, 13.3924,  4.7016,\n",
      "         10.3838,  1.4298],\n",
      "        [ 3.5490,  4.7498,  5.2435,  2.4653,  4.8120,  8.6169,  4.6326,  4.6806,\n",
      "          1.0271,  3.9346],\n",
      "        [ 7.5157,  2.3759,  2.6134,  1.8757,  0.8666, 10.1414,  7.8532,  2.2451,\n",
      "          7.1938,  6.4142],\n",
      "        [ 4.0168,  4.9544,  6.8214,  7.8899,  5.4373, 17.9497, 14.6543,  5.9889,\n",
      "         11.6812,  1.2434],\n",
      "        [ 0.3795,  8.5752,  1.5612,  5.1914,  7.7736,  4.3689,  1.2588,  5.6496,\n",
      "          0.5023,  2.2729],\n",
      "        [ 4.5504, 16.6233,  4.0728, 13.5156, 16.0639,  3.4819,  6.9404, 13.8684,\n",
      "          8.8186,  1.4553]])\n"
     ]
    }
   ],
   "source": [
    "# 作者: Italmassov Kuanysh\n",
    "\n",
    "# 使用了上一题中的 disntance 函数\n",
    "P0 = (torch.rand([10,2])-0.5) * 20\n",
    "P1 = (torch.rand([10,2])-0.5) * 20\n",
    "p = (torch.rand([10,2])-0.5) * 20\n",
    "\n",
    "print(torch.stack([distance(P0,P1,p_i) for p_i in p]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 80. Consider an arbitrary array, write a function that extract a subpart with a fixed shape and centered on a given element (pad with a `fill` value when necessary) (★★★)\n",
    "译者注：没弄懂题目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 9 8 3 1 5 9 6 5 7]\n",
      " [5 1 1 2 2 8 4 6 0 4]\n",
      " [5 0 5 7 1 6 7 6 4 5]\n",
      " [1 7 2 2 6 0 5 9 6 5]\n",
      " [3 5 9 8 8 5 1 3 0 6]\n",
      " [1 1 3 1 9 0 2 9 6 8]\n",
      " [7 4 2 8 7 1 5 2 4 8]\n",
      " [8 3 1 8 1 8 8 8 0 9]\n",
      " [0 0 3 2 0 4 6 1 2 5]\n",
      " [5 5 9 8 2 3 3 5 8 4]]\n",
      "[[0 0 0 0 0]\n",
      " [0 2 9 8 3]\n",
      " [0 5 1 1 2]\n",
      " [0 5 0 5 7]\n",
      " [0 1 7 2 2]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bello/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:26: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n"
     ]
    }
   ],
   "source": [
    "# 原题答案\n",
    "# 作者: Nicolas Rougier\n",
    "\n",
    "Z = np.random.randint(0,10,(10,10))\n",
    "shape = (5,5)\n",
    "fill  = 0\n",
    "position = (1,1)\n",
    "\n",
    "R = np.ones(shape, dtype=Z.dtype)*fill\n",
    "P  = np.array(list(position)).astype(int)\n",
    "Rs = np.array(list(R.shape)).astype(int)\n",
    "Zs = np.array(list(Z.shape)).astype(int)\n",
    "\n",
    "R_start = np.zeros((len(shape),)).astype(int)\n",
    "R_stop  = np.array(list(shape)).astype(int)\n",
    "Z_start = (P-Rs//2)\n",
    "Z_stop  = (P+Rs//2)+Rs%2\n",
    "\n",
    "R_start = (R_start - np.minimum(Z_start,0)).tolist()\n",
    "Z_start = (np.maximum(Z_start,0)).tolist()\n",
    "R_stop = np.maximum(R_start, (R_stop - np.maximum(Z_stop-Zs,0))).tolist()\n",
    "Z_stop = (np.minimum(Z_stop,Zs)).tolist()\n",
    "\n",
    "r = [slice(start,stop) for start,stop in zip(R_start,R_stop)]\n",
    "z = [slice(start,stop) for start,stop in zip(Z_start,Z_stop)]\n",
    "R[r] = Z[z]\n",
    "print(Z)\n",
    "print(R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 81. Consider an array Z = [1,2,3,4,5,6,7,8,9,10,11,12,13,14], how to generate an array R = [[1,2,3,4], [2,3,4,5], [3,4,5,6], ..., [11,12,13,14]]? (★★★)\n",
    "译者注：题同 76，只是将 76 中的一行 3 个元素换成了一行 4 个元素。将 `numpy` 中的 `as_strided`改成 Pytorch 中的 `as_strided` 同样会报错"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3  4]\n",
      " [ 2  3  4  5]\n",
      " [ 3  4  5  6]\n",
      " [ 4  5  6  7]\n",
      " [ 5  6  7  8]\n",
      " [ 6  7  8  9]\n",
      " [ 7  8  9 10]\n",
      " [ 8  9 10 11]\n",
      " [ 9 10 11 12]\n",
      " [10 11 12 13]\n",
      " [11 12 13 14]]\n"
     ]
    }
   ],
   "source": [
    "# 原题答案\n",
    "# 作者: Stefan van der Walt\n",
    "\n",
    "Z = np.arange(1,15,dtype=np.uint32)\n",
    "R = stride_tricks.as_strided(Z,(11,4),(4,4))\n",
    "print(R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 82. 计算一个矩阵的秩 (★★★)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10)\n"
     ]
    }
   ],
   "source": [
    "# 作者: Stefan van der Walt\n",
    "Z = torch.rand((10,10))\n",
    "U, S, V = torch.svd(Z) # Singular Value Decomposition\n",
    "rank = torch.sum(S > 1e-10)\n",
    "print(rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 83. 找出一维 Tensor 中的众数?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9, 0, 1, 1, 0, 7, 6, 5, 7, 8, 5, 4, 0, 1, 3, 6, 3, 7, 1, 5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.return_types.mode(values=tensor(1), indices=tensor(18))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.randint(0,10,[20])\n",
    "print(t)\n",
    "torch.mode(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 84. 从一个 10x10 的矩阵中，提取出所有的连续 3x3 小矩阵 (★★★)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3, 3, 3, 4],\n",
      "        [2, 0, 0, 4],\n",
      "        [4, 0, 4, 2],\n",
      "        [2, 4, 4, 4]])\n",
      "tensor([[[[3, 3, 3],\n",
      "          [2, 0, 0],\n",
      "          [4, 0, 4]],\n",
      "\n",
      "         [[3, 3, 4],\n",
      "          [0, 0, 4],\n",
      "          [0, 4, 2]]],\n",
      "\n",
      "\n",
      "        [[[2, 0, 0],\n",
      "          [4, 0, 4],\n",
      "          [2, 4, 4]],\n",
      "\n",
      "         [[0, 0, 4],\n",
      "          [0, 4, 2],\n",
      "          [4, 4, 4]]]])\n"
     ]
    }
   ],
   "source": [
    "# 作者：Chris Barker\n",
    "Z = torch.randint(0,5,(4,4))  #  译者注：为了避免打印出来的 Tensor 太长，占据太多页面位置，故此处改为 4x4\n",
    "print(Z)\n",
    "n = 3\n",
    "i = 1 + (Z.shape[0]-3)\n",
    "j = 1 + (Z.shape[1]-3)\n",
    "C = torch.as_strided(Z, size=(i, j, n, n), stride=Z.stride() + Z.stride())\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 85. 创建一个 class，输入一个矩阵，将其转换为对称矩阵，同时要确保转换后的对称矩阵任意一个元素修改值后，对称位置元素也要修改 (★★★)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  5, 10, 15],\n",
      "        [ 5, 10, 15, 20],\n",
      "        [10, 15, 20, 25],\n",
      "        [15, 20, 25, 30]])\n",
      "tensor([[ 0,  5, 10, 15],\n",
      "        [ 5, 10, 15, 20],\n",
      "        [10, 15, 20, 42],\n",
      "        [15, 20, 42, 30]])\n"
     ]
    }
   ],
   "source": [
    "class Symetric:\n",
    "    def __init__(self, x):\n",
    "        self.tensor = x + x.T\n",
    "        \n",
    "    def __setitem__(self, index, value):\n",
    "        i,j = index\n",
    "        self.tensor.__setitem__((i,j), value)\n",
    "        self.tensor.__setitem__((j,i), value)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.tensor.__repr__()\n",
    "\n",
    "t = Symetric(torch.arange(16).view((4,4)))\n",
    "print(t)\n",
    "t[2,3] = 42\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 86. Consider a set of p matrices wich shape (n,n) and a set of p vectors with shape (n,1). How to compute the sum of of the p matrix products at once? (result has shape (n,1)) (★★★)\n",
    "译者注：题目似乎没写全。题目看起来似乎和那 p 个 vectors 没有关联……"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 87. 给定一个 16x16 矩阵，如何计算每个子 4x4 矩阵的和? (★★★)\n",
    "译者注：原题答案使用了 `np.add.reduceat`，Pytorch 没有对应函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2., 2.],\n",
       "         [2., 2.]],\n",
       "\n",
       "        [[2., 2.],\n",
       "         [2., 2.]]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 作者: Robert Kern\n",
    "\n",
    "Z = np.ones((16,16))\n",
    "k = 4\n",
    "S = np.add.reduceat(np.add.reduceat(Z, np.arange(0, Z.shape[0], k), axis=0),\n",
    "                                       np.arange(0, Z.shape[1], k), axis=1)\n",
    "print(S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 88. 使用 Tensor 实现生命游戏（Game of Life）(★★★)\n",
    "译者注：生命游戏见 https://zh.wikipedia.org/wiki/%E5%BA%B7%E5%A8%81%E7%94%9F%E5%91%BD%E6%B8%B8%E6%88%8F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 原题答案\n",
    "# 作者: Nicolas Rougier\n",
    "\n",
    "def iterate(Z):\n",
    "    # Count neighbours\n",
    "    N = (Z[0:-2,0:-2] + Z[0:-2,1:-1] + Z[0:-2,2:] +\n",
    "         Z[1:-1,0:-2]                + Z[1:-1,2:] +\n",
    "         Z[2:  ,0:-2] + Z[2:  ,1:-1] + Z[2:  ,2:])\n",
    "\n",
    "    # Apply rules\n",
    "    birth = (N==3) & (Z[1:-1,1:-1]==0)\n",
    "    survive = ((N==2) | (N==3)) & (Z[1:-1,1:-1]==1)\n",
    "    Z[...] = 0\n",
    "    Z[1:-1,1:-1][birth | survive] = 1\n",
    "    return Z\n",
    "\n",
    "Z = np.random.randint(0,2,(50,50))\n",
    "for i in range(100): \n",
    "    Z = iterate(Z)\n",
    "#     print(Z) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 89. 获取一个 Tensor 中前 n 大的数字 (★★★)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(values=tensor([0.9998, 0.9998, 0.9995]), indices=tensor([2612, 7883, 8855]))"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z = torch.rand(10000)\n",
    "n = 3\n",
    "Z.topk(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 90. 给定任意数量的向量，计算所有向量的笛卡儿积(★★★)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 4 6]\n",
      " [1 4 7]\n",
      " [1 5 6]\n",
      " [1 5 7]\n",
      " [2 4 6]\n",
      " [2 4 7]\n",
      " [2 5 6]\n",
      " [2 5 7]\n",
      " [3 4 6]\n",
      " [3 4 7]\n",
      " [3 5 6]\n",
      " [3 5 7]]\n"
     ]
    }
   ],
   "source": [
    "# 原题答案\n",
    "# 作者: Stefan Van der Walt\n",
    "\n",
    "def cartesian(arrays):\n",
    "    arrays = [np.asarray(a) for a in arrays]\n",
    "    shape = (len(x) for x in arrays)\n",
    "\n",
    "    ix = np.indices(shape, dtype=int)\n",
    "    ix = ix.reshape(len(arrays), -1).T\n",
    "\n",
    "    for n, arr in enumerate(arrays):\n",
    "        ix[:, n] = arrays[n][ix[:, n]]\n",
    "\n",
    "    return ix\n",
    "\n",
    "print (cartesian(([1, 2, 3], [4, 5], [6, 7])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 91. How to create a record array from a regular array? (★★★)\n",
    "译者注：使用了 numpy 特有的数据结构 record array。跳过"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 92. 给定一个长向量 Z，用 3 种方法计算 Z 的 3 次方 (★★★)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146 ms ± 4.19 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "312 ms ± 8.61 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "296 ms ± 4.74 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(int(5e7))\n",
    "\n",
    "%timeit torch.pow(x,3)\n",
    "%timeit x*x*x\n",
    "%timeit torch.einsum('i,i,i->i',x,x,x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 93. 给定两个 Tensor A 和 B，尺寸分别为 (8,3) 和 (2,2)。找出 A 中的哪些行包含 B 中所有行的元素。 (★★★)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 94. Considering a 10x3 matrix, extract rows with unequal values (e.g. [2,2,3]) (★★★)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 95. Convert a vector of ints into a matrix binary representation (★★★)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 96. Given a two dimensional array, how to extract unique rows? (★★★)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 97. Considering 2 vectors A & B, write the einsum equivalent of inner, outer, sum, and mul function (★★★)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 98. Considering a path described by two vectors (X,Y), how to sample it using equidistant samples (★★★)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 99. Given an integer n and a 2D array X, select from X the rows which can be interpreted as draws from a multinomial distribution with n degrees, i.e., the rows which only contain integers and which sum to n. (★★★)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 100. Compute bootstrapped 95% confidence intervals for the mean of a 1D array X (i.e., resample the elements of an array with replacement N times, compute the mean of each sample, and then compute percentiles over the means). (★★★)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
